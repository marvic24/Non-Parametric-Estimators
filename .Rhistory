dygraphs::dygraph(pnl_s, main="Back-test of Reverting Strategies")
look_back <- 50
rm(perf_env)
perf_env <- new.env()
process_ed <- eapply(sp500_env, function(oh_lc) {
sym_bol <- rutils::get_name(colnames(oh_lc)[1])
# cat(sym_bol, "\n")
assign(x=sym_bol,
value=backtest_ewma(oh_lc, look_back=look_back, lagg=lagg, thresh_old=thresh_old, co_eff=co_eff),
envir=perf_env)
sym_bol
})  # end eapply
save(perf_env, file="C:/Develop/data/perf_sp500_vwap_lback50.RData")
pnl_s <- eapply(perf_env, function(x_ts) {
if (start(x_ts) < "2017-01-01") {
pnl_s <- x_ts["2010/2017" ,"pnls"]
mean(pnl_s)/sd(pnl_s)
} else NULL
})  # end eapply
pnl_s <- unlist(pnl_s)
pnl_s <- sort(pnl_s, decreasing=TRUE)
sym_bols <- names(pnl_s)
be_st <- lapply(sym_bols[1:20], function(sym_bol) {
get(sym_bol, perf_env)[, "pnls"]
})  # end lapply
names(be_st) <- sym_bols[1:20]
be_st <- rutils::do_call(cbind, be_st)
wo_rst <- lapply(sym_bols[(NROW(sym_bols)-19):NROW(sym_bols)], function(sym_bol) {
get(sym_bol, perf_env)[, "pnls"]
})  # end lapply
wo_rst <- rutils::do_call(cbind, wo_rst)
wo_rst <- (-wo_rst)
pnl_s <- cbind(be_st, wo_rst)
pnl_s[1, is.na(pnl_s[1, ])] <- 0
pnl_s <- zoo::na.locf(pnl_s, na.rm=FALSE)
sum(is.na(pnl_s))
pnl_s <- xts::xts(rowMeans(pnl_s), index(pnl_s))
pnl_s <- cumsum(pnl_s)
dygraphs::dygraph(pnl_s, main="Back-test of Reverting Strategies")
look_back <- 10
rm(perf_env)
perf_env <- new.env()
process_ed <- eapply(sp500_env, function(oh_lc) {
sym_bol <- rutils::get_name(colnames(oh_lc)[1])
# cat(sym_bol, "\n")
assign(x=sym_bol,
value=backtest_ewma(oh_lc, look_back=look_back, lagg=lagg, thresh_old=thresh_old, co_eff=co_eff),
envir=perf_env)
sym_bol
})  # end eapply
save(perf_env, file="C:/Develop/data/perf_sp500_vwap_lback10.RData")
pnl_s <- eapply(perf_env, function(x_ts) {
if (start(x_ts) < "2017-01-01") {
pnl_s <- x_ts["2010/2017" ,"pnls"]
mean(pnl_s)/sd(pnl_s)
} else NULL
})  # end eapply
pnl_s <- unlist(pnl_s)
pnl_s <- sort(pnl_s, decreasing=TRUE)
sym_bols <- names(pnl_s)
be_st <- lapply(sym_bols[1:20], function(sym_bol) {
get(sym_bol, perf_env)[, "pnls"]
})  # end lapply
names(be_st) <- sym_bols[1:20]
be_st <- rutils::do_call(cbind, be_st)
wo_rst <- lapply(sym_bols[(NROW(sym_bols)-19):NROW(sym_bols)], function(sym_bol) {
get(sym_bol, perf_env)[, "pnls"]
})  # end lapply
wo_rst <- rutils::do_call(cbind, wo_rst)
wo_rst <- (-wo_rst)
pnl_s <- cbind(be_st, wo_rst)
pnl_s[1, is.na(pnl_s[1, ])] <- 0
pnl_s <- zoo::na.locf(pnl_s, na.rm=FALSE)
sum(is.na(pnl_s))
pnl_s <- xts::xts(rowMeans(pnl_s), index(pnl_s))
pnl_s <- cumsum(pnl_s)
dygraphs::dygraph(pnl_s, main="Back-test of Reverting Strategies")
rm(perf_env)
lagg
co_eff
## Loop over all sp500 stocks using several parameters
perf_env <- new.env()
process_ed <- eapply(sp500_env, function(oh_lc) {
sym_bol <- rutils::get_name(colnames(oh_lc)[1])
# cat(sym_bol, "\n")
pnl_s <- lapply(5:10, backtest_ewma, oh_lc=oh_lc, lagg=lagg, co_eff=co_eff)
pnl_s <- lapply(pnl_s, function(x) x[, "pnls"])
pnl_s <- do.call(cbind, pnl_s)
assign(x=sym_bol,
value=xts::xts(rowMeans(pnl_s), index(oh_lc)),
envir=perf_env)
sym_bol
})  # end eapply
save(perf_env, file="C:/Develop/data/perf_sp500_vwap_lback510.RData")
foo <- perf_env$AAPL
dygraph(cumsum(foo))
pnl_s <- eapply(perf_env, function(x_ts) {
if (start(x_ts) < "2017-01-01") {
pnl_s <- x_ts["2010/2017"]
mean(pnl_s)/sd(pnl_s)
} else NULL
})  # end eapply
pnl_s <- unlist(pnl_s)
pnl_s <- sort(pnl_s, decreasing=TRUE)
sym_bols <- names(pnl_s)
# Calculate out-of-sample pnls of best stocks from environment
be_st <- lapply(sym_bols[1:20], function(sym_bol) {
get(sym_bol, perf_env)
})  # end lapply
names(be_st) <- sym_bols[1:20]
be_st <- rutils::do_call(cbind, be_st)
wo_rst <- lapply(sym_bols[(NROW(sym_bols)-19):NROW(sym_bols)], function(sym_bol) {
get(sym_bol, perf_env)
})  # end lapply
names(be_st) <- sym_bols[(NROW(sym_bols)-19):NROW(sym_bols)]
wo_rst <- rutils::do_call(cbind, wo_rst)
wo_rst <- (-wo_rst)
pnl_s <- cbind(be_st, wo_rst)
pnl_s[1, is.na(pnl_s[1, ])] <- 0
pnl_s <- zoo::na.locf(pnl_s, na.rm=FALSE)
sum(is.na(pnl_s))
pnl_s <- xts::xts(rowMeans(pnl_s), index(pnl_s))
pnl_s <- cumsum(pnl_s)
dygraphs::dygraph(pnl_s, main="Back-test of Reverting Strategies")
library(HighFreq)
rutils::calc_endpoints
library(HighFreq)
str(data.table::fread)
# Load data with AAPL stock predictive features from csv file
da_ta <- data.table::fread(file="C:/Develop/data/predictive/jerzy_aapl_20200720.csv", stringsAsFactors=FALSE)
dim(da_ta)
head(da_ta)
re_turns <- da_ta$price_change_plus_5min
class(re_turns)
tail(re_turns)
sapply(da_ta, sd)
da_ta <- da_ta[!"price_change_plus_5min"]
da_ta <- da_ta[-"price_change_plus_5min"]
da_ta <- da_ta[-c("price_change_plus_5min")]
dim(da_ta)
da_ta <- da_ta[, -"price_change_plus_5min"]
dim(da_ta)
sapply(da_ta, sd)
sapply(da_ta, mean)
da_ta <- scale(da_ta, center = TRUE, scale = TRUE)
class(da_ta)
dim(da_ta)
apply(da_ta, MARGIN=2, sd)
apply(da_ta, MARGIN=2, mean)
head(da_ta)
tail(da_ta)
cov_mat <- cov(da_ta)
cov_mat
cor_mat <- cor(da_ta)
library(corrplot)
or_der <- corrMatOrder(cor_mat,
order="hclust",
hclust.method="complete")
cor_mat <- cor_mat[or_der, or_der]
col_ors <- colorRampPalette(c("red", "white", "blue"))
x11()
corrplot(cor_mat, title="AAPL Features Correlation Matrix",
tl.col="black", tl.cex=0.8, mar=c(0,0,1,0),
method="square", col=col_ors(8),
cl.offset=0.75, cl.cex=0.7,
cl.align.text="l", cl.ratio=0.25)
# draw rectangles on the correlation matrix plot
corrRect.hclust(cor_mat, k=NROW(cor_mat) %/% 2,
method="complete", col="red")
or_der
# Perform PCA without scaling
pc_a <- prcomp(da_ta, scale=FALSE)
# Plot barplots with PCA weights in multiple panels
x11()
n_weights <- 6
par(mfrow=c(n_weights/2, 2))
par(mar=c(2, 2, 2, 1), oma=c(0, 0, 0, 0))
for (or_der in 1:n_weights) {
barplot(pc_a$rotation[, or_der], las=3, xlab="", ylab="", main="")
title(paste0("PC", or_der), line=-2.0, col.main="red")
} # end for
sum(re_turns)
x11()
plot(re_turns, t="l")
plot(cumsum(re_turns)[100*(1:NROW(re_turns) %/% 100)], t="l")
head(re_turns)
tail(re_turns)
sd(re_turns)
mean(re_turns)
x11()
pacf(re_turns, lag.max=10)
NROW(re_turns)
3600*6.5
NROW(re_turns)/(3600*6.5)
plot(pc_a$x, t="l")
dim(pc_a$x)
plot(pc_a$x[, 1], t="l")
round(cor(pc_a$x), 4)
apply(pc_a$x, MARGIN=2, sd)
# Inspect principal component time series
# Calculate correlations of principal component time series and re_turns
cor_vec <- re_turns*pc_a$x/sd(re_turns)
cor_vec
# Inspect principal component time series
# Calculate correlations of principal component time series and re_turns
cor_vec <- apply(re_turns*pc_a$x, MARGIN=2, sum)/sd(re_turns)
cor_vec
apply(pc_a$x, MARGIN=2, sd)
NROW(re_turns)
dim(pc_a$x)
# Inspect principal component time series
s_d <- apply(pc_a$x, MARGIN=2, sd)
s_d
cor_vec <- apply(re_turns*pc_a$x, MARGIN=2, sum)/sd(re_turns)/s_d
cor_vec
apply(pc_a$x, MARGIN=2, mean)
returns_std <- (re_turns - mean(re_turns))/sd(re_turns)
cor_vec <- apply(returns_std*pc_a$x, MARGIN=2, sum)/s_d
cor_vec
sd(returns_std)
mean(returns_std)
cor_vec <- apply(returns_std*pc_a$x, MARGIN=2, sum)/s_d/NROW(returns_std)
cor_vec
barplot(cor_vec)
s_d*2
weight_s <- cor_vec/s_d*2
barplot(weight_s)
barplot(cor_vec)
barplot(weight_s)
weight_s
cor_vec
weight_s <- cor_vec/s_d^2
weight_s
barplot(weight_s)
FOO <- weight_s
rm(FOO)
foo <- weight_s
object_ive <- function(weight_s, re_turns) {
portf_rets <- re_turns %*% weight_s
-sum(portf_rets^2) +
1e7*(1 - sum(weight_s^2))^2
}  # end object_ive
cor_vec
n_weights
n_weights <- NROW(cor_vec)
n_weights
weight_s <- rep(1/sqrt(n_weights), n_weights)
weight_s
optim_run <- optim(par=weight_s,
fn=object_ive,
re_turns=pc_a$x,
method="L-BFGS-B",
upper=rep(10.0, n_weights),
lower=rep(-10.0, n_weights))
weight_s <- optim_run$par
weight_s
foo
barplot(weight_s)
cor_vec
# Objective function equal to minus portfolio variance
object_ive <- function(weight_s, re_turns) {
-sum(re_turns * weight_s) +
1e7*(1 - sum(weight_s^2))^2
}  # end object_ive
n_weights <- NROW(cor_vec)
weight_s <- rep(1/sqrt(n_weights), n_weights)
optim_run <- optim(par=weight_s,
fn=object_ive,
re_turns=cor_vec,
method="L-BFGS-B",
upper=rep(10.0, n_weights),
lower=rep(-10.0, n_weights))
# Optimal weights and maximum variance
weight_s <- optim_run$par
weight_s
object_ive <- function(weight_s, re_turns) {
-sum(re_turns * weight_s) +
1e7*(1 - sum(weight_s^2))^2
}  # end object_ive
sum(cor_vec * weight_s)
sum(cor_vec * cor_vec)
object_ive <- function(weight_s, re_turns) {
-sum(re_turns * weight_s) +
1e7*(1 - sum(weight_s^2))^2
}  # end object_ive
weight_s <- rep(1, n_weights)
optim_run <- optim(par=weight_s,
fn=object_ive,
re_turns=cor_vec,
method="L-BFGS-B",
upper=rep(10.0, n_weights),
lower=rep(-10.0, n_weights))
weight_s <- optim_run$par
weight_s
weight_s <- weight_s/sqrt(sum(weight_s^2))
sum(weight_s^2)
weight_s
foo <- cor_vec
foo <- foo/sqrt(sum(foo^2))
foo
sum(foo^2)
weight_s
unname(foo)
barplot(weight_s)
barplot(foo)
barplot(weight_s)
weight_s <- foo
barplot(weight_s)
barplot(cor_vec)
apply(pc_a$x, MARGIN=2, mean)
pca_ts <- scale(pc_a$x, center=TRUE, scale=TRUE)
dim(pca_ts)
cor(returns_std, pca_ts)
cor_vec <- apply(returns_std*pca_ts, MARGIN=2, sum)/NROW(returns_std)
cor_vec
rm(list = ls())
# Load data with AAPL stock predictive features from csv file
da_ta <- data.table::fread(file="C:/Develop/data/predictive/jerzy_aapl_20200720.csv", stringsAsFactors=FALSE)
re_turns <- da_ta$price_change_plus_5min
apply(da_ta, MARGIN=2, mean)
apply(da_ta, MARGIN=2, sd)
da_ta <- da_ta[, -"price_change_plus_5min"]
data_scaled <- scale(da_ta, center=TRUE, scale=TRUE)
sd_data <- apply(da_ta, MARGIN=2, sd)
mean_data <- apply(da_ta, MARGIN=2, mean)
# Calculate correlation matrix
cor_mat <- cor(data_scaled)
or_der <- corrMatOrder(cor_mat,
order="hclust",
hclust.method="complete")
cor_mat <- cor_mat[or_der, or_der]
col_ors <- colorRampPalette(c("red", "white", "blue"))
x11()
corrplot(cor_mat, title="AAPL Features Correlation Matrix",
tl.col="black", tl.cex=0.8, mar=c(0,0,1,0),
method="square", col=col_ors(8),
cl.offset=0.75, cl.cex=0.7,
cl.align.text="l", cl.ratio=0.25)
corrRect.hclust(cor_mat, k=NROW(cor_mat) %/% 2,
method="complete", col="red")
pc_a <- prcomp(data_scaled, scale=FALSE)
returns_std <- (re_turns - mean(re_turns))/sd(re_turns)
s_d <- apply(pc_a$x, MARGIN=2, sd)
cor_vec <- cor(re_turns, pc_a$x)
cor_vec
weight_s <- cor_vec
weight_s <- cor_vec/s_d
weight_s
x11()
barplot(weight_s)
cor_vec
pc_a$rotation
inv_rotation <- solve(pc_a$rotation)
inv_rotation
sol_ved <- weight_s %*% inv_rotation
sol_ved
sol_ved <- drop(weight_s %*% inv_rotation)
sol_ved
foo <- data_scaled %*% sol_ved
dim(foo)
foo <- drop(data_scaled %*% sol_ved)
cor(re_turns, foo)
cor_vec
cor_vec <- drop(cor_vec)
cor_vec
max(cor_vec)
sqrt(sum(cor_vec^2))
weights_solved <- sol_ved
rm(sol_ved)
weights_solved
barplot(weights_solved)
weights_solved <- drop(weight_s %*% inv_rotation)
weights_solved <- weights_solved/sd_data
foo <- drop(da_ta %*% weights_solved)
cor(re_turns, foo)
weights_solved
dim(da_ta)
foo <- drop(da_ta %*% weights_solved)
class(da_ta)
foo <- drop(as.matrix(da_ta) %*% weights_solved)
cor(re_turns, foo)
barplot(weights_solved)
cor_vec
da_ta <- as.matrix(da_ta)
cor_vec <- cor(re_turns, da_ta)
cor_vec
cor_vec <- drop(cor(re_turns, da_ta))
cor_vec
range(cor_vec)
weights_solved
barplot(weights_solved)
round(weights_solved, 6)
cor_vec <- drop(cor(re_turns, da_ta))
barplot(cor_vec)
barplot(cor_vec, main="Correlations of Features to the AAPL Returns")
barplot(weights_solved, main="Weights of Features in New Feature")
matrix(round(weights_solved, 6), nc=1)
foo <- round(weights_solved, 6)
foo
matrix(round(weights_solved, 6), nc=1, dimnames=c(names(weights_solved), "weights"))
matrix(round(weights_solved, 6), nc=1, dimnames=list(names(weights_solved), "weights"))
library(HighFreq)
da_ta <- data.table::fread(file="C:/Develop/data/predictive/jerzy_aapl_20200720.csv", stringsAsFactors=FALSE)
re_turns <- da_ta$price_change_plus_5min
cor_vec <- drop(cor(re_turns, da_ta))
cor_vec
which.max(cor_vec)
which.max(cor_vec[-1])
which.max(abs(cor_vec[-1]))
position_s <- rep(NA_integer_, NROW(re_turns))
position_s[1] <- 0
ls()
indica_tor <- da_ta[feature5]
indica_tor <- da_ta[, feature5]
tail(indica_tor)
range(indica_tor)
tail(indica_tor, 33)
tail(da_ta[, feature4], 33)
indica_tor <- (da_ta[, feature4] + da_ta[, feature5])
sum(is.na(indica_tor))
range(indica_tor)
position_s <- indica_tor
position_s <- rutils::lag_it(position_s, lagg=1)
co_eff <- (-1)
pnl_s <- cumsum(co_eff*re_turns*position_s)
tail(pnl_s)
NROW(re_turns) %/% 1e3
x11()
plot(pnl_s(1e3*(1:(NROW(re_turns) %/% 1e3))), t="l")
plot(pnl_s[(1e3*(1:(NROW(re_turns) %/% 1e3)))], t="l")
position_s <- zoo::na.locf(position_s, na.rm=FALSE)
plot(pnl_s[(1e3*(1:(NROW(re_turns) %/% 1e3)))], t="l")
colnames(da_ta)
cor_vec <- drop(cor(rutils::lag_it(re_turns, lagg=(-1)), da_ta))
cor_vec
cor_vec <- drop(cor(rutils::lag_it(re_turns, lagg=(-10)), da_ta))
cor_vec
library(HighFreq)
library(microbenchmark)
R CMD Rd2pdf C:\Develop\capstone\Sumit Sethi\package
system("R CMD Rd2pdf C:\Develop\capstone\Sumit Sethi\package")
system("R CMD Rd2pdf C:/Develop/capstone/Sumit Sethi/package")
devtools::install_github(repo="marvic24/Non-Parametric-Estimators")
search()
q()
install.packages(c("Rcpp", "RcppArmadillo"))
install.packages("RcppParallel")
devtools::install_github(repo="marvic24/Non-Parametric-Estimators")
library(NPE)
search()
ls()
library(NPE)
da_ta <- rnorm(1e3)
med_ian(da_ta)
search()
median(da_ta)
summary(microbenchmark(
rcpp=med_ian(da_ta),
rcode=median(da_ta),
times=10))[, c(1, 4, 5)]
library(microbenchmark)
summary(microbenchmark(
rcpp=med_ian(da_ta),
rcode=median(da_ta),
times=10))[, c(1, 4, 5)]
ls(NPE)
search()
ls("package:NPE")
x <- round(runif(10), 2)
y <- round(runif(10), 2)
all.equal(wilcox.test(x, y)$p.value, drop(NPE::WilcoxanMannWhitneyTest(x, y)))
summary(microbenchmark(
rcpp=WilcoxanMannWhitneyTest(x, y),
rcode=wilcox.test(x, y),
times=10))[, c(1, 4, 5)]  # end microbenchmark summary
library(Rcpp)
install.packages(pkgs="C:/Develop/capstone/Sumit_Sethi/NPE", repos=NULL, type="source")
detach("NPE")
search()
detach("package:NPE")
search()
install.packages(pkgs="C:/Develop/capstone/Sumit_Sethi/NPE", repos=NULL, type="source")
install.packages(pkgs="C:/Develop/capstone/Sumit_Sethi/NPE", repos=NULL, type="source")
library(NPE)
all.equal(wilcox.test(x, y)$p.value, drop(NPE::WilcoxanMannWhitneyTest(x, y)))
re_turns <- rnorm(1e6)
all.equal(drop(NPE::med_ian(re_turns)), median(re_turns))
args(roll::roll_median)
args(NPE::rolling_median)
all.equal(drop(NPE::rolling_median(re_turns, look_back=11)),
roll::roll_median(re_turns, width=11))
foo <- roll::roll_median(re_turns, width=11)
head(foo, 13)
all.equal(drop(NPE::rolling_median(re_turns, look_back=11))[-(1:10)],
roll::roll_median(re_turns, width=11)[-(1:10)])
summary(microbenchmark(
parallel_rcpp=NPE::rolling_median(re_turns),
rcpp=roll::roll_median(re_turns),
times=10))[, c(1, 4, 5)]  # end microbenchmark summary
summary(microbenchmark(
parallel_rcpp=NPE::rolling_median(re_turns, look_back=11),
rcpp=roll::roll_median(re_turns, width=11),
times=10))[, c(1, 4, 5)]  # end microbenchmark summary
getwd()
setwd("C:/Develop/capstone/Sumit_Sethi/NPE")
devtools::document()
system("R CMD Rd2pdf C:/Develop/capstone/Sumit_Sethi/NPE")
setwd("C:/Develop/R/scripts")
setwd("C:/Develop/capstone/Sumit_Sethi/NPE")
devtools::document()
system("R CMD Rd2pdf C:/Develop/capstone/Sumit_Sethi/NPE")
q()
