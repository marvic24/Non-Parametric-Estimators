# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Worker function for calculating median over rolling window by using parallel processing.
NULL

#' Worker function for calculating median absolute deviation over rolling window
#' by using parallel processing.
NULL

#' Worker function for calculating skewness of the colums of time series over
#' rolling window by using parallel processing.
NULL

#' Worker function for calculating pair averages needed for Hodges-Lehmann
#' estimator by using parallel processing.
NULL

#' Calculate the median of a  \emph{vector} or a single-column \emph{time
#' series} using \code{RcppArmadillo}.
#'
#' @param \code{vec_tor} A \emph{vector} or a single-column \emph{time series}.
#'
#' @return A single \emph{double} value representing median of the vector.
#'
#' @details The function \code{med_ian()} calculates the median of the
#'   \emph{vector}, using \code{RcppArmadillo}. The function \code{med_ian()}
#'   is several times faster than \code{median()} in \code{R}.
#'
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- na.omit(NPE::etf_env$re_turns[ ,"VTI"])
#' # Compare med_ian() with median()
#' all.equal(drop(NPE::med_ian(re_turns)), 
#'   median(re_turns))
#' # Compare the speed of RcppArmadillo with R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   Rcpp=NPE::med_ian(re_turns),
#'   Rcode=median(re_turns),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
med_ian <- function(vec_tor) {
    .Call(`_NPE_med_ian`, vec_tor)
}

#' Calculate the rolling median over a \emph{vector} or a single-column \emph{time series}
#' using \code{RcppArmadillo} and \code{RcppParallel}.
#' 
#' @param \code{vec_tor} A \emph{vector} or a single-column \emph{time series}.
#' @param \code{look_back} The length of look back interval, equal to the
#'   number of elements of data used for calculating the median.
#'   
#' @return A column \emph{vector} of the same length as the argument
#'   \code{vect_tor}.
#'
#' @details The function \code{rolling_median()} calculates a vector of
#'   rolling medians, over a \emph{vector} of data, using \emph{RcppArmadillo}
#'   and \emph{RcppParallel}. The function \code{rolling_median()} is faster
#'   than \code{roll::roll_median()} which uses \code{Rcpp}.
#'
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- na.omit(NPE::etf_env$re_turns[ ,"VTI"])
#' # Compare rolling_median() with roll::roll_median()
#' all.equal(drop(NPE::rolling_median(re_turns, look_back=11))[-(1:10)], 
#'   zoo::coredata(roll::roll_median(re_turns, width=11))[-(1:10)])
#' # Compare the speed of RcppArmadillo with R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   parallel_rcpp=NPE::rolling_median(re_turns, look_back=11),
#'   roll=roll::roll_median(re_turns, width=11),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
rolling_median <- function(vec_tor, look_back) {
    .Call(`_NPE_rolling_median`, vec_tor, look_back)
}

#' Calculate the Median Absolute Deviations (\emph{MAD}) of the columns of a
#' \emph{time series} or a \emph{matrix} using \code{RcppArmadillo}.
#'
#' @param \code{t_series} A \emph{time series} or a \emph{matrix} of data.
#'
#' @return A single-row matrix with the Median Absolute Deviations \emph{MAD}
#'   of the columns of \code{t_series}.
#'
#' @details The function \code{calc_mad()} calculates the Median Absolute
#'   Deviations \emph{MAD} of the columns of a \emph{time series} or a
#'   \emph{matrix} of data using \code{RcppArmadillo} \code{C++} code.
#'
#'   The function \code{calc_mad()} performs the same calculation as the
#'   function \code{stats::mad()}, but it's much faster because it uses
#'   \code{RcppArmadillo} \code{C++} code.
#'
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- na.omit(NPE::etf_env$re_turns[ ,"VTI", drop=FALSE])
#' # Compare calc_mad() with stats::mad()
#' all.equal(drop(NPE::calc_mad(re_turns)), 
#'   mad(re_turns)/1.4826)
#' # Compare the speed of RcppArmadillo with stats::mad()
#' library(microbenchmark)
#' summary(microbenchmark(
#'   Rcpp=NPE::calc_mad(re_turns),
#'   Rcode=mad(re_turns),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
calc_mad <- function(t_series) {
    .Call(`_NPE_calc_mad`, t_series)
}

#' Calculate the rolling median absolute deviation over a \emph{vector} or a
#' single-column \emph{time series} using \code{RcppArmadillo} and
#' \code{RcppParallel}.
#' 
#' @param \code{vec_tor} A \emph{vector} or a single-column \emph{time series}.
#' @param \code{look_back} The length of look back interval, equal to the
#'   number of elements of data used for calculating the median.
#'   
#' @return A column \emph{vector} of the same length as the argument
#'   \code{vect_tor}.
#'
#' @details The function \code{rolling_mad()} calculates a vector of
#'   rolling medians, over a \emph{vector} of data, using \emph{RcppArmadillo}
#'   and \emph{RcppParallel}. 
#'   
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- na.omit(NPE::etf_env$re_turns[ ,"VTI"])
#' # Define R function for the rolling MAD
#' rolling_madr <- function(x, look_back) {
#'   sapply(1:NROW(x), function(i) {
#'     NPE::calc_mad(x[max(1, i-look_back+1):i, ])
#'   })  # end sapply
#' }  # end rolling_madr
#' # Compare rolling_mad() with R code
#' all.equal(drop(NPE::rolling_mad(re_turns, 11))[-(1:10)],
#'   rolling_madr(re_turns, 11)[-(1:10)], check.attributes=FALSE)
#' # Compare the speed of RcppArmadillo with R code
#' summary(microbenchmark(
#'   parallel_Rcpp=NPE::rolling_mad(re_turns, 11),
#'   Rcode=rolling_madr(re_turns, 11),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
rolling_mad <- function(vec_tor, look_back) {
    .Call(`_NPE_rolling_mad`, vec_tor, look_back)
}

#' Calculate the skewness of the columns of a \emph{time series} or a
#' \emph{matrix} using \code{RcppArmadillo}.
#'
#' @param \code{t_series} A \emph{time series} or a \emph{matrix} of data.
#'
#' @param \code{typ_e} A \emph{string} specifying the type of skewness (see
#'   Details). (The default is the \code{typ_e = "pearson"}.)
#'
#' @param \code{al_pha} The confidence level for calculating the quantiles.
#'   (the default is \code{al_pha = 0.25}).
#'
#' @return A single-row matrix with the skewness of the columns of
#'   \code{t_series}.
#'
#' @details The function \code{calc_skew()} calculates the skewness of the
#'   columns of a \emph{time series} or a \emph{matrix} of data using
#'   \code{RcppArmadillo} \code{C++} code.
#'
#'   If \code{typ_e = "pearson"} (the default) then \code{calc_skew()}
#'   calculates the Pearson skewness using the third moment of the data.
#'
#'   If \code{typ_e = "quantile"} then it calculates the skewness using the
#'   differences between the quantiles of the data.
#'
#'   If \code{typ_e = "nonparametric"} then it calculates the skewness as the
#'   difference between the mean of the data minus its median, divided by the
#'   standard deviation.
#'   
#'   The code examples below compare the function \code{calc_skew()} with the
#'   skewness calculated using \code{R} code.
#'
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- na.omit(NPE::etf_env$re_turns[ ,"VTI", drop=FALSE])
#' # Calculate the Pearson skewness
#' NPE::calc_skew(re_turns)
#' # Compare NPE::calc_skew() with Pearson skewness
#' calc_skewr <- function(x) {
#'   x <- (x-mean(x)); nr <- NROW(x);
#'   nr*sum(x^3)/(var(x))^1.5/(nr-1)/(nr-2)
#' }  # end calc_skewr
#' all.equal(NPE::calc_skew(re_turns, typ_e = "pearson"), 
#'   calc_skewr(re_turns), check.attributes=FALSE)
#' # Compare the speed of RcppArmadillo with R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   Rcpp=NPE::calc_skew(re_turns, typ_e = "pearson"),
#'   Rcode=calc_skewr(re_turns),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' # Calculate the quantile skewness
#' NPE::calc_skew(re_turns, typ_e = "quantile", al_pha = 0.1)
#' # Compare NPE::calc_skew() with quantile skewness
#' calc_skewq <- function(x) {
#'   	quantile_s <- quantile(x, c(0.25, 0.5, 0.75), type=5)
#'   	(quantile_s[3] + quantile_s[1] - 2*quantile_s[2])/(quantile_s[3] - quantile_s[1])
#' }  # end calc_skewq
#' all.equal(drop(NPE::calc_skew(re_turns, typ_e = "quantile")), 
#'   calc_skewq(re_turns), check.attributes=FALSE)
#' # Compare the speed of RcppArmadillo with R code
#' summary(microbenchmark(
#'   Rcpp=NPE::calc_skew(re_turns, typ_e = "quantile"),
#'   Rcode=calc_skewq(re_turns),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' # Calculate the nonparametric skewness
#' NPE::calc_skew(re_turns, typ_e = "nonparametric")
#' # Compare NPE::calc_skew() with R nonparametric skewness
#' all.equal(drop(NPE::calc_skew(re_turns, typ_e = "nonparametric")), 
#'   (mean(re_turns)-median(re_turns))/sd(re_turns), 
#'   check.attributes=FALSE)
#' # Compare the speed of RcppArmadillo with R code
#' summary(microbenchmark(
#'   Rcpp=NPE::calc_skew(re_turns, typ_e = "nonparametric"),
#'   Rcode=(mean(re_turns)-median(re_turns))/sd(re_turns),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
calc_skew <- function(t_series, typ_e = "pearson", al_pha = 0.25) {
    .Call(`_NPE_calc_skew`, t_series, typ_e, al_pha)
}

#' Calculate the skewness of the columns of a \emph{time series} or a
#' \emph{matrix} over a rolling window using \code{RcppArmadillo} and
#' \code{RcppParallel}.
#'
#' @param \code{t_series} A \emph{time series} or a \emph{matrix} of data.
#'
#' @param \code{look_back} The length of look back interval.
#' 
#' @param \code{typ_e} A \emph{string} specifying the type of skewness (see
#'   Details). (The default is the \code{typ_e = "pearson"}.)
#'
#' @param \code{al_pha} The confidence level for calculating the quantiles.
#'   (the default is \code{al_pha = 0.25}).
#'
#' @return A matrix with the skewness of the columns of
#'   \code{t_series} over rolling window.
#'
#' @details The function \code{rolling_skew()} calculates the skewness of the
#'   columns of a \emph{time series} or a \emph{matrix} of data using
#'   \code{RcppArmadillo} and \code{RcppParallel} \code{C++} code.
#'
#'   If \code{typ_e = "pearson"} (the default) then \code{calc_skew()}
#'   calculates the Pearson skewness using the third moment of the data.
#'
#'   If \code{typ_e = "quantile"} then it calculates the skewness using the
#'   differences between the quantiles of the data.
#'
#'   If \code{typ_e = "nonparametric"} then it calculates the skewness as the
#'   difference between the mean of the data minus its median, divided by the
#'   standard deviation.
#'   
#'   The code examples below compare the function \code{rolling_skew()} with the
#'   skewness calculated using \code{R} code.
#'
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- na.omit(NPE::etf_env$re_turns[ ,"VTI", drop=FALSE])
#' # Define R function for the rolling skew
#' rolling_skewr <- function(x, look_back) {
#'   sapply(1:NROW(x), function(i) {
#'     NPE::calc_skew(x[max(1, i-look_back+1):i, ])
#'   })  # end sapply
#' }  # end rolling_skewr
#' # Compare rolling_skew() with R code
#' all.equal(drop(NPE::rolling_skew(re_turns, 11))[-(1:10)],
#'   rolling_skewr(re_turns, 11)[-(1:10)], check.attributes=FALSE)
#' # Compare the speed of RcppArmadillo with R code
#' summary(microbenchmark(
#'   parallel_Rcpp=NPE::rolling_skew(re_turns, 11),
#'   Rcode=rolling_skewr(re_turns, 11),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' 
#' @export
rolling_skew <- function(t_series, look_back, typ_e = "pearson", al_pha = 0.25) {
    .Call(`_NPE_rolling_skew`, t_series, look_back, typ_e, al_pha)
}

#' Calculate the nonparametric Hodges-Lehmann estimator of location for a
#' \emph{vector} or a single-column \emph{time series} using \code{RcppArmadillo}
#' and \code{RcppParallel}.
#' 
#' @param \code{vec_tor} A \emph{vector} or a single-column \emph{time series}.
#' 
#' @return A single \emph{double} value representing Hodges-Lehmann estimator of 
#'   the vector.
#'
#' @details The function \code{hle()} calculates the Hodges-Lehmann estimator of 
#'   the \emph{vector}, using \code{RcppArmadillo} and \code{RcppParallel}. The 
#'   function \code{hle()} is very much faster than function \code{wilcox.test()}
#'   in \code{R}.
#'
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- as.numeric(na.omit(NPE::etf_env$re_turns[ ,"VTI"]))
#' # Compare hle() with wilcox.test() - equal only approximately
#' all.equal(wilcox.test(re_turns, conf.int = TRUE)$estimate, 
#'   drop(NPE::hle(re_turns)), check.attributes=FALSE)
#' # Install package ICSNP for nonparametric statistics
#' install.packages("ICSNP")
#' # Compare hle() with ICSNP::hl.loc() - almost equal
#' all.equal(ICSNP::hl.loc(re_turns), 
#'   drop(NPE::hle(re_turns)), check.attributes=FALSE)
#' # Compare the speed of RcppParallel with R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   Rcpp=NPE::hle(re_turns),
#'   Rcode=wilcox.test(re_turns, conf.int = TRUE),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
hle <- function(vec_tor) {
    .Call(`_NPE_hle`, vec_tor)
}

#' Calculate the nonparametric Theil-Sen estimator of dependency-covariance for
#' two \emph{vectors} using \code{RcppArmadillo}
#'
#' @param \code{vector_x} A \emph{vector} independent (explanatory) data.
#' @param \code{vector_y} A \emph{vector} dependent data.
#'
#' @return A column \emph{vector} containing two values i.e intercept and
#'   slope.
#'
#' @details The function \code{theilSenEstimator()} calculates the Theil-Sen
#'   estimator  using \code{RcppArmadillo}. The function
#'   \code{theilSenEstimator()} is significantly faster than function
#'   \code{WRS::tsreg()} in \code{R}.
#'
#' @examples
#' \dontrun{
#' # Create vectors of random returns
#' vector_x <- rnorm(10)
#' vector_y <- rnorm(10)
#' # Install package akima and WRS
#' install.packages("akima")
#' install.packages("WRS", repos="http://R-Forge.R-project.org")
#' # Compare theilSenEstimator() with WRS::tsreg()
#' all.equal(NPE::theilSenEstimator(vector_x, vector_y), 
#'   WRS::tsreg(vector_x, vector_y, FALSE)$coef, check.attributes=FALSE)
#' # Compare the speed of RcppParallel with R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   Rcpp=NPE::theilSenEstimator(vector_x, vector_y),
#'   Rcode=WRS::tsreg(vector_x, vector_y, FALSE),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
theilSenEstimator <- function(x, y) {
    .Call(`_NPE_theilSenEstimator`, x, y)
}

#' Performs a principal component analysis on given \emph{matrix} or \emph{time
#' series} using \code{RcppArmadillo}.
#'
#' @param \code{mat_rix} A \emph{matrix} or a \emph{time series}.
#'
#' @return A \emph{matrix} of variable loadings (i.e. a matrix whose columns
#'   contain the eigenvectors).
#'
#' @details The function \code{calc_pca()} performs a principal component
#'   analysis on a \emph{matrix} using \code{RcppArmadillo}.
#'   
#' @examples
#' \dontrun{
#' 
#' # Select all the ETF symbols except "VXX" and "SVXY"
#' sym_bols <- NPE::etf_env$sym_bols
#' sym_bols <- sym_bols[!(sym_bols %in% c("VXX", "SVXY"))]
#' # Calculate ETF returns
#' re_turns <- NPE::etf_env$re_turns[, sym_bols]
#' re_turns <- na.omit(re_turns)
#' # Compare calc_pca() with standard prcomp()
#' all.equal(NPE::calc_pca(re_turns), 
#'   stats::prcomp(re_turns)$rotation, check.attributes=FALSE)
#' # Compare the speed of RcppArmadillo with R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   Rcpp=NPE::calc_pca(re_turns),
#'   Rcode=prcomp(re_turns),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
calc_pca <- function(mat_rix) {
    .Call(`_NPE_calc_pca`, mat_rix)
}

#' Calculate the medcouple of a  \emph{vector} or a single-column \emph{time
#' series} using \code{Rcpp}.
#' 
#' @param \code{vec_tor} A \emph{vector} or a single-column \emph{time series}.
#' @param \code{eps1} A \emph{double} Tolerance of the algorithm.
#' @param \code{eps2} A \emph{double} Tolerance of the algorithm..
#' 
#' 
#' @return A single \emph{double} value representing medcouple of the vector.
#'
#' @details The function \code{med_couple()} calculates the medcouple of the \emph{vector},
#'   using \code{Rcpp}. The function \code{med_couple()} is several times faster
#'   than \code{mc()} in package \code{robustbase}.
#'
#' @examples
#' \dontrun{
#' # Calculate VTI returns
#' re_turns <- na.omit(NPE::etf_env$re_turns[ ,"VTI"])
#' # Compare med_couple() with mc()
#' all.equal(drop(NPE::med_couple(re_turns)), 
#'   robustbase::mc(re_turns))
#' # Compare the speed of NPE with Robustbase code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   Rcpp=NPE::med_couple(re_turns),
#'   robustbase=robustbase::mc(re_turns),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
med_couple <- function(x, eps1 = 1e-14, eps2 = 1e-15) {
    .Call(`_NPE_med_couple`, x, eps1, eps2)
}

#' This is an overload of a function \code{calc_ranksWithTies()}, which returns ranks of
#' the \emph{vector} or a single column \emph{time-series}. It also returns a \code{boolean}
#' variable indicating if there are ties in the data or not.
#' There is a function for calculating ranks in rcpp::armadillo, but it doesn't handle ties!
NULL

#' This function calculates the p values using normal approximation in case 
#' 1. exact calculation is not requested and sample size is greater than 50.
#' 2. There are ties in the data.
NULL

#' Calculate the ranks of the elements of a \emph{vector} or a single-column
#' \emph{time series} using \code{RcppArmadillo} and \code{boost}.
#' 
#' @param \code{vec_tor} A \emph{vector} or a single-column \emph{time series}.
#' 
#' @return A \emph{double vector} with the ranks of the elements of the
#'   \emph{vector}.
#' 
#' @details The function \code{calc_ranks()} calculates the ranks of the
#'   elements of a \emph{vector} or a single-column \emph{time series}.
#'   It \emph{averages} the ranks in case fo ties.
#'   It uses the \code{boost} function \code{boost::sort::parallel_stable_sort}
#'   for sorting array in parallel fashion.
#' 
#' @examples
#' \dontrun{
#' # Create a vector of random data
#' da_ta <- round(runif (7), 2)
#' # Calculate the ranks of the elements in two ways
#' all.equal(rank(da_ta), drop(NPE::calc_ranksWithTies(da_ta)))
#' # Create a time series of random data
#' da_ta <- xts::xts(runif (7), seq.Date(Sys.Date(), by=1, length.out=7))
#' # Calculate the ranks of the elements in two ways
#' all.equal(rank(coredata(da_ta)), drop(NPE::calc_ranksWithTies(da_ta)))
#' # Compare the speed of this function with RcppArmadillo and R code
#' da_ta <- runif (7)
#' library(microbenchmark)
#' summary(microbenchmark(
#'   rcpp=calc_ranks(da_ta),
#'   rcode=rank(da_ta),
#'   boost=calc_ranksWithTies(da_ta) 
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
calc_ranksWithTies <- function(vec_tor) {
    .Call(`_NPE_calc_ranksWithTies`, vec_tor)
}

#' Performs one sample Wilcoxan ranked sum test on \emph{vector} or a single-column
#' \emph{time series} using \code{RcppArmadillo} and \code{boost}.
#' 
#' @param \code{x} A \emph{vector} or a single-column \emph{time series}.
#' @param \code{mu} A \emph{double} specifing an optional parameter used 
#'   to form null hypothesis. Default value is \emph{zero}.
#' @param \code{alternative} a \emph{character} string specifying the alternative
#'   hypothesis. It must be one of :
#'   \itemize{
#'     \item "two.sided" two tailed test.
#'     \item "greater" greater(right) tailed test.
#'     \item "less" smaller(left) tailed test.
#'   }
#'   (The default is \emph{two.sided} test.)
#' @param \code{exact} A {boolean} indicating whether an exact p-value should be computed.
#' @param \code{correct} A {boolean} indicating whether to apply continuity correction
#'   in normal approximation for the p-value.  
#' 
#' @return A \emph{double} indicating p-value of the test.
#' 
#' @details The function \code{wilcoxanSignedRankTest()} carries out the wilcoxan signed 
#'   rank test on \emph{vec_tor} and returns the \emph{p-value} of the test.
#'   By default (if \code{exact} is not specified), an exact p-value is computed if sample 
#'   contains less than 50 finite values and there are no ties. Otherwise, a normal approximation
#'   is used.
#' 
#' @examples
#' \dontrun{
#' # Create a vector of random data
#' da_ta <- round(runif (7), 2)
#' # Carry out wilcoxan signed rank test on the elements in two ways
#' all.equal(wilcox.test(da_ta)$p.value, drop(HighFreq::WilcoxanSignedRankTest(da_ta)))
#' # Create a time series of random data
#' da_ta <- xts::xts(runif (7), seq.Date(Sys.Date(), by=1, length.out=7))
#' # Calculate the ranks of the elements in two ways
#' all.equal(wilcox.test(coredata(da_ta))$p.value, drop(NPE::wilcoxanSignedRankTest(da_ta)))
#' # Compare the speed of Rcpp and R code
#' da_ta <- runif (10)
#' library(microbenchmark)
#' summary(microbenchmark(
#'   rcpp=wilcoxanSignedRankTest(da_ta),
#'   rcode=wilcox.test(da_ta),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
wilcoxanSignedRankTest <- function(x, mu = 0, alternative = "two.sided", exact = FALSE, correct = TRUE) {
    .Call(`_NPE_wilcoxanSignedRankTest`, x, mu, alternative, exact, correct)
}

#' Performs two sample Wilcoxan-Mann-Whitney rank sum test also known as 
#' Mann-Whitney U Test on \emph{vector} or a single-column \emph{time series}
#' using \code{RcppArmadillo} and \code{boost}.
#' 
#' @param \code{x} A \emph{vector} or a single-column \emph{time series}.
#' @param \code{y} A \emph{vector} or a single-column \emph{time series}.
#' @param \code{mu} A \emph{double} specifing an optional parameter used 
#'   to form null hypothesis. Default value is \emph{zero}.
#' @param \code{alternative} a \emph{character} string specifying the alternative
#'   hypothesis. It must be one of :
#'   \itemize{
#'     \item "two.sided" two tailed test.
#'     \item "greater" greater(right) tailed test.
#'     \item "less" smaller(left) tailed test.
#'   }
#'   (The default is \emph{two.sided} test.)
#' @param \code{exact} A {boolean} indicating whether an exact p-value should be computed.
#' @param \code{correct} A {boolean} indicating whether to apply continuity correction
#'   in normal approximation for the p-value.  
#' 
#' @return A \emph{double} indicating p-value of the test.
#' 
#' @details The function \code{wilcoxanMannWhitneyTest()} carries out the wilcoxan-Mann-Whitney
#'   signed rank test on \emph{x} & \emph{y} and returns the \emph{p-value} of the test.
#'   By default (if \code{exact} is not specified), an exact p-value is computed if sample 
#'   contains less than 50 finite values and there are no ties. Otherwise, a normal approximation
#'   is used.
#' 
#' @examples
#' \dontrun{
#' # Create a vector of random data
#' x <- round(runif (10), 2)
#' y <- round(runif (10), 2)
#' # Carry out WMW signed rank test on the elements in two ways
#' all.equal(wilcox.test(x, y)$p.value, drop(NPE::wilcoxanMannWhitneyTest(x, y)))
#' # Compare the speed of Rcpp and R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   rcpp=wilcoxanMannWhitneyTest(x, y),
#'   rcode=wilcox.test(x, y),
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
wilcoxanMannWhitneyTest <- function(x, y, mu = 0, alternative = "two.sided", exact = FALSE, correct = TRUE) {
    .Call(`_NPE_wilcoxanMannWhitneyTest`, x, y, mu, alternative, exact, correct)
}

#' Performs a Kruskal-Wallis rank sum test. using \code{Rcpp} and \code{boost}.
#' 
#' @param \code{x} A \emph{List} of numeric data vectors
#' 
#' @return A \emph{double} indicating p-value of the test.
#' 
#' @details The function \code{kruskalWalliceTest()} performs a Kruskal-Wallis rank 
#'   sum test of the null hypothesis that the location parameters of the distribution
#'   of x are the same in each group. The alternative is that they differ in
#'   at least in one.
#' 
#' @examples
#' \dontrun{
#' x <- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
#' y <- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
#' z <- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
#' 
#' # Carry out Kruskal wallice rank sum test on the elements in two ways
#' all.equal(kruskal.test(list(x, y, z))$p.value, drop(NPE::kruskalWalliceTest(list(x, y, z))))
#' # Compare the speed of Rcpp and R code
#' library(microbenchmark)
#' summary(microbenchmark(
#'   rcpp=kruskalWalliceTest(list(x, y, z)),
#'   rcode=kruskal.test(list(x, y, z))$p.value,
#'   times=10))[, c(1, 4, 5)]  # end microbenchmark summary
#' }
#' 
#' @export
kruskalWalliceTest <- function(x) {
    .Call(`_NPE_kruskalWalliceTest`, x)
}

